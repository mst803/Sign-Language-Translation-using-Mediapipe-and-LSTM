{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Neccesory Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation And Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_frames_from_directory(directory):\n",
    "    img_id=[]\n",
    "    img_path=[]\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        # temparary image and path\n",
    "        ti=[]\n",
    "        tp=[]\n",
    "        for file in files:\n",
    "            \n",
    "            # Check if the file is an image file\n",
    "            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                frame_path = os.path.join(root, file)\n",
    "                \n",
    "                if file not in ti:\n",
    "                    ti.append(file)\n",
    "                    tp.append(frame_path)\n",
    "                    \n",
    "        if ti:\n",
    "            img_id.append(ti)\n",
    "            img_path.append(tp)\n",
    "                    \n",
    "    return img_id,img_path\n",
    "\n",
    "All_image_id,All_image_path=load_frames_from_directory('Frames_Sentence_Level')\n",
    "\n",
    "\n",
    "df1=pd.read_csv('corpus_csv_files\\\\ISL Corpus sign glosses.csv')\n",
    "df2=pd.read_excel('corpus_csv_files\\\\ISL_CSLRT_Corpus_frame_details.xlsx')\n",
    "\n",
    "data_num=len(All_image_path)\n",
    "\n",
    "captions = []\n",
    "\n",
    "for i in range(len(All_image_path)):\n",
    "\n",
    "    if 'ISL_CSLRT_Corpus\\\\' + All_image_path[i][0] in df2['Frames path'].values:\n",
    "        word_value = df2.loc[df2['Frames path'] == 'ISL_CSLRT_Corpus\\\\' + All_image_path[i][0], 'Sentence'].values\n",
    "        sign_gloss = df1.loc[df1['Sentence'] == word_value[0], 'SIGN GLOSSES'].values\n",
    "        if sign_gloss.size<=0:\n",
    "            sign_gloss=np.array([word_value[0].upper()])\n",
    "        \n",
    "    else:\n",
    "        sign_gloss = np.array([\"No caption found\"])\n",
    "        \n",
    "    captions.append('<start> '+sign_gloss[0]+' <end>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the labels to numerical values\n",
    "y = label_encoder.fit_transform(captions)\n",
    "labels = to_categorical(y).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('New_class.pkl', 'wb') as file:\n",
    "    pickle.dump(label_encoder.classes_,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence=np.load('new_seq.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sequence\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(621, 211)\n",
      "(621, 30, 258)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 30, 256)           527360    \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 98)                25186     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,340,770\n",
      "Trainable params: 1,340,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense , Dropout, Flatten\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add LSTM layer with return_sequences=True for time-distributed behavior\n",
    "model.add(LSTM(units=256, input_shape=(30, 258), return_sequences=True))\n",
    "model.add(LSTM(units=256, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=98, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "18/18 [==============================] - 14s 418ms/step - loss: 5.3583 - accuracy: 0.0018 - val_loss: 5.3288 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "18/18 [==============================] - 6s 337ms/step - loss: 5.1751 - accuracy: 0.0072 - val_loss: 5.3430 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "18/18 [==============================] - 6s 346ms/step - loss: 5.1271 - accuracy: 0.0072 - val_loss: 5.3125 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 5.0793 - accuracy: 0.0018 - val_loss: 5.3329 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "18/18 [==============================] - 7s 360ms/step - loss: 5.0473 - accuracy: 0.0143 - val_loss: 5.3189 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "18/18 [==============================] - 5s 302ms/step - loss: 5.0326 - accuracy: 0.0108 - val_loss: 5.3566 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "18/18 [==============================] - 6s 330ms/step - loss: 5.0267 - accuracy: 0.0090 - val_loss: 5.4496 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "18/18 [==============================] - 6s 311ms/step - loss: 5.0330 - accuracy: 0.0072 - val_loss: 5.3850 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "18/18 [==============================] - 4s 236ms/step - loss: 5.0076 - accuracy: 0.0108 - val_loss: 5.3789 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "18/18 [==============================] - 5s 273ms/step - loss: 4.9971 - accuracy: 0.0036 - val_loss: 5.4856 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "18/18 [==============================] - 5s 288ms/step - loss: 4.9863 - accuracy: 0.0090 - val_loss: 5.3501 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "18/18 [==============================] - 5s 306ms/step - loss: 4.9707 - accuracy: 0.0072 - val_loss: 5.3391 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "18/18 [==============================] - 4s 232ms/step - loss: 4.9381 - accuracy: 0.0143 - val_loss: 5.3315 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "18/18 [==============================] - 4s 226ms/step - loss: 4.9905 - accuracy: 0.0215 - val_loss: 5.3699 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "18/18 [==============================] - 4s 227ms/step - loss: 4.9408 - accuracy: 0.0054 - val_loss: 5.2495 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "18/18 [==============================] - 4s 231ms/step - loss: 4.9062 - accuracy: 0.0179 - val_loss: 5.3088 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "18/18 [==============================] - 4s 227ms/step - loss: 4.8825 - accuracy: 0.0143 - val_loss: 5.3133 - val_accuracy: 0.0317\n",
      "Epoch 18/300\n",
      "18/18 [==============================] - 4s 236ms/step - loss: 4.8232 - accuracy: 0.0108 - val_loss: 5.3303 - val_accuracy: 0.0159\n",
      "Epoch 19/300\n",
      "18/18 [==============================] - 4s 229ms/step - loss: 4.8226 - accuracy: 0.0143 - val_loss: 5.2652 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "18/18 [==============================] - 4s 228ms/step - loss: 4.7943 - accuracy: 0.0090 - val_loss: 5.2996 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "18/18 [==============================] - 4s 234ms/step - loss: 4.7118 - accuracy: 0.0197 - val_loss: 5.4960 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/300\n",
      "18/18 [==============================] - 4s 238ms/step - loss: 4.7474 - accuracy: 0.0179 - val_loss: 5.6399 - val_accuracy: 0.0159\n",
      "Epoch 23/300\n",
      "18/18 [==============================] - 4s 228ms/step - loss: 4.7101 - accuracy: 0.0161 - val_loss: 5.6020 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/300\n",
      "18/18 [==============================] - 4s 239ms/step - loss: 4.6499 - accuracy: 0.0251 - val_loss: 5.4980 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/300\n",
      "18/18 [==============================] - 5s 253ms/step - loss: 4.5754 - accuracy: 0.0251 - val_loss: 5.5335 - val_accuracy: 0.0159\n",
      "Epoch 26/300\n",
      "18/18 [==============================] - 4s 249ms/step - loss: 4.5335 - accuracy: 0.0215 - val_loss: 5.3956 - val_accuracy: 0.0159\n",
      "Epoch 27/300\n",
      "18/18 [==============================] - 5s 254ms/step - loss: 4.5408 - accuracy: 0.0215 - val_loss: 5.3713 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/300\n",
      "18/18 [==============================] - 4s 229ms/step - loss: 4.4440 - accuracy: 0.0305 - val_loss: 5.6686 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/300\n",
      "18/18 [==============================] - 4s 234ms/step - loss: 4.3842 - accuracy: 0.0197 - val_loss: 5.9472 - val_accuracy: 0.0159\n",
      "Epoch 30/300\n",
      "18/18 [==============================] - 5s 268ms/step - loss: 4.3794 - accuracy: 0.0376 - val_loss: 5.6921 - val_accuracy: 0.0317\n",
      "Epoch 31/300\n",
      "18/18 [==============================] - 5s 294ms/step - loss: 4.2516 - accuracy: 0.0502 - val_loss: 5.7156 - val_accuracy: 0.0476\n",
      "Epoch 32/300\n",
      "18/18 [==============================] - 6s 345ms/step - loss: 4.2902 - accuracy: 0.0341 - val_loss: 5.8499 - val_accuracy: 0.0317\n",
      "Epoch 33/300\n",
      "18/18 [==============================] - 6s 306ms/step - loss: 4.2129 - accuracy: 0.0430 - val_loss: 5.6397 - val_accuracy: 0.0317\n",
      "Epoch 34/300\n",
      "18/18 [==============================] - 5s 277ms/step - loss: 4.1659 - accuracy: 0.0484 - val_loss: 5.8245 - val_accuracy: 0.0317\n",
      "Epoch 35/300\n",
      "18/18 [==============================] - 5s 270ms/step - loss: 4.0353 - accuracy: 0.0735 - val_loss: 5.9824 - val_accuracy: 0.0317\n",
      "Epoch 36/300\n",
      "18/18 [==============================] - 5s 250ms/step - loss: 4.0845 - accuracy: 0.0609 - val_loss: 5.8234 - val_accuracy: 0.0476\n",
      "Epoch 37/300\n",
      "18/18 [==============================] - 5s 295ms/step - loss: 4.0314 - accuracy: 0.0645 - val_loss: 5.7529 - val_accuracy: 0.0159\n",
      "Epoch 38/300\n",
      "18/18 [==============================] - 5s 263ms/step - loss: 4.0096 - accuracy: 0.0502 - val_loss: 5.7531 - val_accuracy: 0.0317\n",
      "Epoch 39/300\n",
      "18/18 [==============================] - 5s 268ms/step - loss: 3.9109 - accuracy: 0.0717 - val_loss: 6.0734 - val_accuracy: 0.0317\n",
      "Epoch 40/300\n",
      "18/18 [==============================] - 5s 289ms/step - loss: 3.9063 - accuracy: 0.0663 - val_loss: 5.8706 - val_accuracy: 0.0476\n",
      "Epoch 41/300\n",
      "18/18 [==============================] - 5s 253ms/step - loss: 3.8566 - accuracy: 0.0860 - val_loss: 6.3334 - val_accuracy: 0.0317\n",
      "Epoch 42/300\n",
      "18/18 [==============================] - 4s 241ms/step - loss: 3.8014 - accuracy: 0.0735 - val_loss: 6.4477 - val_accuracy: 0.0159\n",
      "Epoch 43/300\n",
      "18/18 [==============================] - 5s 251ms/step - loss: 3.6615 - accuracy: 0.1075 - val_loss: 6.5015 - val_accuracy: 0.0159\n",
      "Epoch 44/300\n",
      "18/18 [==============================] - 4s 245ms/step - loss: 3.6334 - accuracy: 0.1004 - val_loss: 6.3893 - val_accuracy: 0.0317\n",
      "Epoch 45/300\n",
      "18/18 [==============================] - 4s 247ms/step - loss: 3.5474 - accuracy: 0.1147 - val_loss: 6.6775 - val_accuracy: 0.0317\n",
      "Epoch 46/300\n",
      "18/18 [==============================] - 5s 252ms/step - loss: 3.4810 - accuracy: 0.1219 - val_loss: 6.7442 - val_accuracy: 0.0159\n",
      "Epoch 47/300\n",
      "18/18 [==============================] - 4s 250ms/step - loss: 3.4344 - accuracy: 0.1219 - val_loss: 6.6573 - val_accuracy: 0.0317\n",
      "Epoch 48/300\n",
      "18/18 [==============================] - 5s 255ms/step - loss: 3.4050 - accuracy: 0.1201 - val_loss: 6.7325 - val_accuracy: 0.0159\n",
      "Epoch 49/300\n",
      "18/18 [==============================] - 5s 303ms/step - loss: 3.3719 - accuracy: 0.1290 - val_loss: 6.8870 - val_accuracy: 0.0159\n",
      "Epoch 50/300\n",
      "18/18 [==============================] - 5s 269ms/step - loss: 3.2612 - accuracy: 0.1720 - val_loss: 7.1432 - val_accuracy: 0.0159\n",
      "Epoch 51/300\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 3.2910 - accuracy: 0.1470 - val_loss: 6.8633 - val_accuracy: 0.0159\n",
      "Epoch 52/300\n",
      "18/18 [==============================] - 5s 301ms/step - loss: 3.1963 - accuracy: 0.1559 - val_loss: 7.4521 - val_accuracy: 0.0159\n",
      "Epoch 53/300\n",
      "18/18 [==============================] - 6s 324ms/step - loss: 3.1445 - accuracy: 0.1828 - val_loss: 7.3220 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/300\n",
      "18/18 [==============================] - 6s 331ms/step - loss: 3.0081 - accuracy: 0.1810 - val_loss: 7.6589 - val_accuracy: 0.0317\n",
      "Epoch 55/300\n",
      "18/18 [==============================] - 5s 295ms/step - loss: 2.9720 - accuracy: 0.1900 - val_loss: 7.5128 - val_accuracy: 0.0159\n",
      "Epoch 56/300\n",
      "18/18 [==============================] - 6s 309ms/step - loss: 2.8378 - accuracy: 0.2115 - val_loss: 7.9585 - val_accuracy: 0.0159\n",
      "Epoch 57/300\n",
      "18/18 [==============================] - 5s 256ms/step - loss: 2.8405 - accuracy: 0.2384 - val_loss: 7.7263 - val_accuracy: 0.0476\n",
      "Epoch 58/300\n",
      "18/18 [==============================] - 6s 328ms/step - loss: 2.7851 - accuracy: 0.2384 - val_loss: 7.8487 - val_accuracy: 0.0317\n",
      "Epoch 59/300\n",
      "18/18 [==============================] - 6s 311ms/step - loss: 2.6266 - accuracy: 0.2455 - val_loss: 8.3123 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/300\n",
      "18/18 [==============================] - 5s 284ms/step - loss: 2.5695 - accuracy: 0.2921 - val_loss: 8.2910 - val_accuracy: 0.0317\n",
      "Epoch 61/300\n",
      "18/18 [==============================] - 5s 284ms/step - loss: 2.5809 - accuracy: 0.2491 - val_loss: 8.1032 - val_accuracy: 0.0317\n",
      "Epoch 62/300\n",
      "18/18 [==============================] - 4s 251ms/step - loss: 2.5759 - accuracy: 0.2903 - val_loss: 8.4214 - val_accuracy: 0.0476\n",
      "Epoch 63/300\n",
      "18/18 [==============================] - 4s 241ms/step - loss: 2.5056 - accuracy: 0.2903 - val_loss: 7.9794 - val_accuracy: 0.0317\n",
      "Epoch 64/300\n",
      "18/18 [==============================] - 4s 240ms/step - loss: 2.3393 - accuracy: 0.2993 - val_loss: 8.4941 - val_accuracy: 0.0317\n",
      "Epoch 65/300\n",
      "18/18 [==============================] - 4s 242ms/step - loss: 2.1720 - accuracy: 0.3925 - val_loss: 8.6495 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/300\n",
      "18/18 [==============================] - 4s 240ms/step - loss: 2.2163 - accuracy: 0.3441 - val_loss: 9.2375 - val_accuracy: 0.0317\n",
      "Epoch 67/300\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 2.1653 - accuracy: 0.3530 - val_loss: 9.0653 - val_accuracy: 0.0317\n",
      "Epoch 68/300\n",
      "18/18 [==============================] - 5s 252ms/step - loss: 2.0851 - accuracy: 0.3602 - val_loss: 9.1316 - val_accuracy: 0.0159\n",
      "Epoch 69/300\n",
      "18/18 [==============================] - 5s 254ms/step - loss: 1.9633 - accuracy: 0.4032 - val_loss: 9.2619 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/300\n",
      "18/18 [==============================] - 5s 281ms/step - loss: 1.9132 - accuracy: 0.4480 - val_loss: 9.9962 - val_accuracy: 0.0159\n",
      "Epoch 71/300\n",
      "18/18 [==============================] - 6s 318ms/step - loss: 1.9155 - accuracy: 0.4140 - val_loss: 9.6848 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/300\n",
      "18/18 [==============================] - 5s 283ms/step - loss: 1.9872 - accuracy: 0.3996 - val_loss: 9.7424 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/300\n",
      "18/18 [==============================] - 5s 251ms/step - loss: 1.9326 - accuracy: 0.3943 - val_loss: 9.4603 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/300\n",
      "18/18 [==============================] - 5s 252ms/step - loss: 1.7605 - accuracy: 0.4588 - val_loss: 9.6460 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/300\n",
      "18/18 [==============================] - 4s 249ms/step - loss: 1.7258 - accuracy: 0.4498 - val_loss: 9.9071 - val_accuracy: 0.0317\n",
      "Epoch 76/300\n",
      "18/18 [==============================] - 5s 283ms/step - loss: 1.6469 - accuracy: 0.4910 - val_loss: 10.4096 - val_accuracy: 0.0159\n",
      "Epoch 77/300\n",
      "18/18 [==============================] - 5s 282ms/step - loss: 1.6296 - accuracy: 0.4875 - val_loss: 10.3627 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/300\n",
      "18/18 [==============================] - 6s 329ms/step - loss: 1.7112 - accuracy: 0.4677 - val_loss: 10.0984 - val_accuracy: 0.0159\n",
      "Epoch 79/300\n",
      "18/18 [==============================] - 5s 271ms/step - loss: 1.6686 - accuracy: 0.4946 - val_loss: 10.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/300\n",
      "18/18 [==============================] - 5s 256ms/step - loss: 1.5982 - accuracy: 0.5018 - val_loss: 9.8282 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/300\n",
      "18/18 [==============================] - 4s 247ms/step - loss: 1.4458 - accuracy: 0.5520 - val_loss: 10.4552 - val_accuracy: 0.0159\n",
      "Epoch 82/300\n",
      "18/18 [==============================] - 5s 256ms/step - loss: 1.4283 - accuracy: 0.5448 - val_loss: 10.3604 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/300\n",
      "18/18 [==============================] - 5s 255ms/step - loss: 1.3969 - accuracy: 0.5502 - val_loss: 10.5157 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/300\n",
      "18/18 [==============================] - 4s 246ms/step - loss: 1.4288 - accuracy: 0.5323 - val_loss: 10.9292 - val_accuracy: 0.0159\n",
      "Epoch 85/300\n",
      "18/18 [==============================] - 4s 240ms/step - loss: 1.3154 - accuracy: 0.5753 - val_loss: 11.2990 - val_accuracy: 0.0317\n",
      "Epoch 86/300\n",
      "18/18 [==============================] - 5s 261ms/step - loss: 1.2972 - accuracy: 0.5860 - val_loss: 10.7480 - val_accuracy: 0.0159\n",
      "Epoch 87/300\n",
      "18/18 [==============================] - 4s 243ms/step - loss: 1.2306 - accuracy: 0.6147 - val_loss: 11.1375 - val_accuracy: 0.0159\n",
      "Epoch 88/300\n",
      "18/18 [==============================] - 4s 242ms/step - loss: 1.2212 - accuracy: 0.6004 - val_loss: 11.4066 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/300\n",
      "18/18 [==============================] - 5s 255ms/step - loss: 1.1641 - accuracy: 0.6290 - val_loss: 11.8754 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/300\n",
      "18/18 [==============================] - 4s 249ms/step - loss: 1.1521 - accuracy: 0.6165 - val_loss: 12.4293 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/300\n",
      "18/18 [==============================] - 4s 240ms/step - loss: 1.2252 - accuracy: 0.6201 - val_loss: 12.1744 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/300\n",
      "18/18 [==============================] - 4s 243ms/step - loss: 1.0632 - accuracy: 0.6308 - val_loss: 11.8961 - val_accuracy: 0.0159\n",
      "Epoch 93/300\n",
      "18/18 [==============================] - 4s 243ms/step - loss: 1.0422 - accuracy: 0.6756 - val_loss: 12.3265 - val_accuracy: 0.0159\n",
      "Epoch 94/300\n",
      "18/18 [==============================] - 4s 241ms/step - loss: 1.0460 - accuracy: 0.6613 - val_loss: 11.8461 - val_accuracy: 0.0159\n",
      "Epoch 95/300\n",
      "18/18 [==============================] - 4s 243ms/step - loss: 1.0790 - accuracy: 0.6559 - val_loss: 11.9775 - val_accuracy: 0.0159\n",
      "Epoch 96/300\n",
      "18/18 [==============================] - 4s 239ms/step - loss: 0.9447 - accuracy: 0.6810 - val_loss: 12.2990 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/300\n",
      "18/18 [==============================] - 5s 251ms/step - loss: 0.8747 - accuracy: 0.7115 - val_loss: 12.8881 - val_accuracy: 0.0317\n",
      "Epoch 98/300\n",
      "18/18 [==============================] - 4s 249ms/step - loss: 0.9856 - accuracy: 0.6971 - val_loss: 13.2403 - val_accuracy: 0.0159\n",
      "Epoch 99/300\n",
      "18/18 [==============================] - 4s 240ms/step - loss: 1.0355 - accuracy: 0.6595 - val_loss: 12.7228 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/300\n",
      "18/18 [==============================] - 4s 244ms/step - loss: 0.9425 - accuracy: 0.6846 - val_loss: 12.9071 - val_accuracy: 0.0159\n",
      "Epoch 101/300\n",
      "18/18 [==============================] - 4s 244ms/step - loss: 0.8820 - accuracy: 0.7204 - val_loss: 13.0069 - val_accuracy: 0.0317\n",
      "Epoch 102/300\n",
      "18/18 [==============================] - 4s 242ms/step - loss: 0.9818 - accuracy: 0.6810 - val_loss: 13.3706 - val_accuracy: 0.0317\n",
      "Epoch 103/300\n",
      "18/18 [==============================] - 4s 241ms/step - loss: 0.7807 - accuracy: 0.7473 - val_loss: 13.5819 - val_accuracy: 0.0317\n",
      "Epoch 104/300\n",
      "18/18 [==============================] - 5s 253ms/step - loss: 0.8311 - accuracy: 0.7294 - val_loss: 13.1501 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/300\n",
      "18/18 [==============================] - 4s 241ms/step - loss: 0.8256 - accuracy: 0.7294 - val_loss: 13.8662 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/300\n",
      "18/18 [==============================] - 4s 243ms/step - loss: 0.8637 - accuracy: 0.7312 - val_loss: 12.9649 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/300\n",
      "18/18 [==============================] - 4s 241ms/step - loss: 0.8200 - accuracy: 0.7384 - val_loss: 13.1695 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/300\n",
      "18/18 [==============================] - 4s 238ms/step - loss: 0.7204 - accuracy: 0.7599 - val_loss: 13.7301 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/300\n",
      "18/18 [==============================] - 4s 242ms/step - loss: 0.6583 - accuracy: 0.7778 - val_loss: 13.6643 - val_accuracy: 0.0159\n",
      "Epoch 110/300\n",
      "18/18 [==============================] - 4s 238ms/step - loss: 0.6340 - accuracy: 0.7903 - val_loss: 14.0205 - val_accuracy: 0.0159\n",
      "Epoch 111/300\n",
      "18/18 [==============================] - 4s 247ms/step - loss: 0.6265 - accuracy: 0.7993 - val_loss: 13.9757 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/300\n",
      "18/18 [==============================] - 4s 251ms/step - loss: 0.6382 - accuracy: 0.8011 - val_loss: 13.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/300\n",
      "18/18 [==============================] - 4s 246ms/step - loss: 0.6156 - accuracy: 0.7885 - val_loss: 14.2635 - val_accuracy: 0.0317\n",
      "Epoch 114/300\n",
      "18/18 [==============================] - 4s 240ms/step - loss: 0.6096 - accuracy: 0.7814 - val_loss: 14.6545 - val_accuracy: 0.0159\n",
      "Epoch 115/300\n",
      "18/18 [==============================] - 4s 249ms/step - loss: 0.6148 - accuracy: 0.7921 - val_loss: 14.6007 - val_accuracy: 0.0159\n",
      "Epoch 116/300\n",
      "18/18 [==============================] - 4s 248ms/step - loss: 0.5650 - accuracy: 0.7957 - val_loss: 14.7942 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/300\n",
      "18/18 [==============================] - 5s 256ms/step - loss: 0.6361 - accuracy: 0.7849 - val_loss: 14.7190 - val_accuracy: 0.0159\n",
      "Epoch 118/300\n",
      "18/18 [==============================] - 4s 244ms/step - loss: 0.6071 - accuracy: 0.8047 - val_loss: 14.6296 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/300\n",
      "18/18 [==============================] - 4s 241ms/step - loss: 0.8812 - accuracy: 0.7330 - val_loss: 13.7080 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/300\n",
      "18/18 [==============================] - 5s 260ms/step - loss: 0.7881 - accuracy: 0.7348 - val_loss: 13.2078 - val_accuracy: 0.0317\n",
      "Epoch 121/300\n",
      "18/18 [==============================] - 4s 246ms/step - loss: 0.6727 - accuracy: 0.7706 - val_loss: 14.1778 - val_accuracy: 0.0476\n",
      "Epoch 122/300\n",
      "18/18 [==============================] - 5s 260ms/step - loss: 0.6930 - accuracy: 0.7634 - val_loss: 14.2679 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/300\n",
      "18/18 [==============================] - 5s 262ms/step - loss: 0.6228 - accuracy: 0.7814 - val_loss: 13.8889 - val_accuracy: 0.0159\n",
      "Epoch 124/300\n",
      "18/18 [==============================] - 5s 262ms/step - loss: 0.6129 - accuracy: 0.7796 - val_loss: 14.4870 - val_accuracy: 0.0159\n",
      "Epoch 125/300\n",
      "18/18 [==============================] - 5s 264ms/step - loss: 0.5807 - accuracy: 0.7939 - val_loss: 14.6519 - val_accuracy: 0.0317\n",
      "Epoch 126/300\n",
      "18/18 [==============================] - 5s 265ms/step - loss: 0.5082 - accuracy: 0.8244 - val_loss: 14.4795 - val_accuracy: 0.0317\n",
      "Epoch 127/300\n",
      "18/18 [==============================] - 5s 258ms/step - loss: 0.4317 - accuracy: 0.8602 - val_loss: 14.2553 - val_accuracy: 0.0159\n",
      "Epoch 128/300\n",
      "18/18 [==============================] - 4s 245ms/step - loss: 0.4331 - accuracy: 0.8566 - val_loss: 14.4508 - val_accuracy: 0.0159\n",
      "Epoch 129/300\n",
      "18/18 [==============================] - 4s 247ms/step - loss: 0.4934 - accuracy: 0.8513 - val_loss: 14.6549 - val_accuracy: 0.0317\n",
      "Epoch 130/300\n",
      "18/18 [==============================] - 5s 252ms/step - loss: 0.4177 - accuracy: 0.8548 - val_loss: 14.7082 - val_accuracy: 0.0476\n",
      "Epoch 131/300\n",
      "18/18 [==============================] - 4s 248ms/step - loss: 0.4313 - accuracy: 0.8548 - val_loss: 14.9147 - val_accuracy: 0.0159\n",
      "Epoch 132/300\n",
      "18/18 [==============================] - 5s 255ms/step - loss: 0.4264 - accuracy: 0.8584 - val_loss: 15.0588 - val_accuracy: 0.0476\n",
      "Epoch 133/300\n",
      "18/18 [==============================] - 5s 251ms/step - loss: 0.4924 - accuracy: 0.8477 - val_loss: 15.0357 - val_accuracy: 0.0317\n",
      "Epoch 134/300\n",
      "18/18 [==============================] - 5s 256ms/step - loss: 0.5191 - accuracy: 0.8226 - val_loss: 15.2422 - val_accuracy: 0.0317\n",
      "Epoch 135/300\n",
      "18/18 [==============================] - 5s 254ms/step - loss: 0.4697 - accuracy: 0.8405 - val_loss: 15.4362 - val_accuracy: 0.0317\n",
      "Epoch 136/300\n",
      "18/18 [==============================] - 5s 279ms/step - loss: 0.4976 - accuracy: 0.8405 - val_loss: 15.3550 - val_accuracy: 0.0635\n",
      "Epoch 137/300\n",
      "18/18 [==============================] - 5s 258ms/step - loss: 0.4718 - accuracy: 0.8477 - val_loss: 14.7537 - val_accuracy: 0.0317\n",
      "Epoch 138/300\n",
      "18/18 [==============================] - 4s 236ms/step - loss: 0.4578 - accuracy: 0.8477 - val_loss: 15.1815 - val_accuracy: 0.0159\n",
      "Epoch 139/300\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.4757 - accuracy: 0.8333 - val_loss: 15.0952 - val_accuracy: 0.0317\n",
      "Epoch 140/300\n",
      "18/18 [==============================] - 4s 244ms/step - loss: 0.4106 - accuracy: 0.8620 - val_loss: 15.3766 - val_accuracy: 0.0159\n",
      "Epoch 141/300\n",
      "18/18 [==============================] - 4s 249ms/step - loss: 0.4159 - accuracy: 0.8602 - val_loss: 15.9876 - val_accuracy: 0.0476\n",
      "Epoch 142/300\n",
      "18/18 [==============================] - 4s 241ms/step - loss: 0.3919 - accuracy: 0.8656 - val_loss: 15.8654 - val_accuracy: 0.0317\n",
      "Epoch 143/300\n",
      "18/18 [==============================] - 4s 239ms/step - loss: 0.3909 - accuracy: 0.8692 - val_loss: 15.6588 - val_accuracy: 0.0159\n",
      "Epoch 144/300\n",
      "18/18 [==============================] - 4s 251ms/step - loss: 0.3895 - accuracy: 0.8763 - val_loss: 15.5873 - val_accuracy: 0.0476\n",
      "Epoch 145/300\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.3636 - accuracy: 0.8817 - val_loss: 14.9890 - val_accuracy: 0.0159\n",
      "Epoch 146/300\n",
      "18/18 [==============================] - 4s 241ms/step - loss: 0.4145 - accuracy: 0.8656 - val_loss: 16.2093 - val_accuracy: 0.0159\n",
      "Epoch 147/300\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.3972 - accuracy: 0.8638 - val_loss: 15.5610 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/300\n",
      "18/18 [==============================] - 4s 238ms/step - loss: 0.3540 - accuracy: 0.8692 - val_loss: 15.4687 - val_accuracy: 0.0317\n",
      "Epoch 149/300\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.3033 - accuracy: 0.9104 - val_loss: 15.6970 - val_accuracy: 0.0317\n",
      "Epoch 150/300\n",
      "18/18 [==============================] - 4s 242ms/step - loss: 0.3700 - accuracy: 0.8674 - val_loss: 15.3967 - val_accuracy: 0.0159\n",
      "Epoch 151/300\n",
      "18/18 [==============================] - 4s 249ms/step - loss: 0.3122 - accuracy: 0.9068 - val_loss: 16.2466 - val_accuracy: 0.0317\n",
      "Epoch 152/300\n",
      "18/18 [==============================] - 4s 243ms/step - loss: 0.2992 - accuracy: 0.8871 - val_loss: 16.2931 - val_accuracy: 0.0317\n",
      "Epoch 153/300\n",
      "18/18 [==============================] - 4s 246ms/step - loss: 0.3047 - accuracy: 0.8996 - val_loss: 17.3630 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/300\n",
      "18/18 [==============================] - 4s 240ms/step - loss: 0.2464 - accuracy: 0.9122 - val_loss: 16.5267 - val_accuracy: 0.0159\n",
      "Epoch 155/300\n",
      "18/18 [==============================] - 4s 240ms/step - loss: 0.3079 - accuracy: 0.8907 - val_loss: 16.9193 - val_accuracy: 0.0317\n",
      "Epoch 156/300\n",
      "18/18 [==============================] - 4s 249ms/step - loss: 0.3438 - accuracy: 0.8853 - val_loss: 16.4114 - val_accuracy: 0.0317\n",
      "Epoch 157/300\n",
      "18/18 [==============================] - 4s 248ms/step - loss: 0.2712 - accuracy: 0.9176 - val_loss: 16.5911 - val_accuracy: 0.0159\n",
      "Epoch 158/300\n",
      "18/18 [==============================] - 5s 253ms/step - loss: 0.3265 - accuracy: 0.8889 - val_loss: 16.6598 - val_accuracy: 0.0317\n",
      "Epoch 159/300\n",
      "18/18 [==============================] - 6s 330ms/step - loss: 0.3826 - accuracy: 0.8674 - val_loss: 16.9539 - val_accuracy: 0.0476\n",
      "Epoch 160/300\n",
      "18/18 [==============================] - 5s 257ms/step - loss: 0.3995 - accuracy: 0.8710 - val_loss: 16.8530 - val_accuracy: 0.0317\n",
      "Epoch 161/300\n",
      "18/18 [==============================] - 4s 250ms/step - loss: 0.3378 - accuracy: 0.8996 - val_loss: 16.4497 - val_accuracy: 0.0317\n",
      "Epoch 162/300\n",
      "18/18 [==============================] - 4s 236ms/step - loss: 0.2679 - accuracy: 0.9122 - val_loss: 16.0124 - val_accuracy: 0.0317\n",
      "Epoch 163/300\n",
      "18/18 [==============================] - 4s 241ms/step - loss: 0.2578 - accuracy: 0.9104 - val_loss: 16.1498 - val_accuracy: 0.0317\n",
      "Epoch 164/300\n",
      "18/18 [==============================] - 5s 266ms/step - loss: 0.2978 - accuracy: 0.8978 - val_loss: 17.1249 - val_accuracy: 0.0317\n",
      "Epoch 165/300\n",
      "18/18 [==============================] - 5s 278ms/step - loss: 0.2878 - accuracy: 0.9068 - val_loss: 16.8237 - val_accuracy: 0.0317\n",
      "Epoch 166/300\n",
      "18/18 [==============================] - 5s 265ms/step - loss: 0.4132 - accuracy: 0.8674 - val_loss: 16.4084 - val_accuracy: 0.0476\n",
      "Epoch 167/300\n",
      "18/18 [==============================] - 4s 240ms/step - loss: 0.3443 - accuracy: 0.8799 - val_loss: 16.8250 - val_accuracy: 0.0317\n",
      "Epoch 168/300\n",
      "18/18 [==============================] - 4s 241ms/step - loss: 0.4220 - accuracy: 0.8638 - val_loss: 16.0246 - val_accuracy: 0.0476\n",
      "Epoch 169/300\n",
      "18/18 [==============================] - 5s 252ms/step - loss: 0.5012 - accuracy: 0.8477 - val_loss: 16.2611 - val_accuracy: 0.0317\n",
      "Epoch 170/300\n",
      "18/18 [==============================] - 5s 277ms/step - loss: 0.3011 - accuracy: 0.8996 - val_loss: 16.1515 - val_accuracy: 0.0635\n",
      "Epoch 171/300\n",
      "18/18 [==============================] - 5s 282ms/step - loss: 0.2935 - accuracy: 0.8978 - val_loss: 15.5943 - val_accuracy: 0.0476\n",
      "Epoch 172/300\n",
      "18/18 [==============================] - 5s 257ms/step - loss: 0.3122 - accuracy: 0.9140 - val_loss: 15.6181 - val_accuracy: 0.0317\n",
      "Epoch 173/300\n",
      "18/18 [==============================] - 4s 238ms/step - loss: 0.3350 - accuracy: 0.8925 - val_loss: 15.6496 - val_accuracy: 0.0159\n",
      "Epoch 174/300\n",
      "18/18 [==============================] - 5s 270ms/step - loss: 0.3537 - accuracy: 0.8817 - val_loss: 15.6539 - val_accuracy: 0.0317\n",
      "Epoch 175/300\n",
      "18/18 [==============================] - 5s 269ms/step - loss: 0.3083 - accuracy: 0.8907 - val_loss: 16.2368 - val_accuracy: 0.0317\n",
      "Epoch 176/300\n",
      "18/18 [==============================] - 5s 269ms/step - loss: 0.2999 - accuracy: 0.9086 - val_loss: 16.1759 - val_accuracy: 0.0317\n",
      "Epoch 177/300\n",
      "18/18 [==============================] - 5s 261ms/step - loss: 0.3123 - accuracy: 0.9014 - val_loss: 15.6220 - val_accuracy: 0.0317\n",
      "Epoch 178/300\n",
      "18/18 [==============================] - 4s 245ms/step - loss: 0.3089 - accuracy: 0.9068 - val_loss: 15.5674 - val_accuracy: 0.0635\n",
      "Epoch 179/300\n",
      "18/18 [==============================] - 4s 244ms/step - loss: 0.3147 - accuracy: 0.9068 - val_loss: 16.1966 - val_accuracy: 0.0476\n",
      "Epoch 180/300\n",
      "18/18 [==============================] - 4s 240ms/step - loss: 0.2439 - accuracy: 0.9122 - val_loss: 16.6568 - val_accuracy: 0.0317\n",
      "Epoch 181/300\n",
      "18/18 [==============================] - 4s 235ms/step - loss: 0.1977 - accuracy: 0.9337 - val_loss: 16.8684 - val_accuracy: 0.0476\n",
      "Epoch 182/300\n",
      "18/18 [==============================] - 4s 240ms/step - loss: 0.1930 - accuracy: 0.9301 - val_loss: 17.2039 - val_accuracy: 0.0317\n",
      "Epoch 183/300\n",
      "18/18 [==============================] - 4s 236ms/step - loss: 0.1940 - accuracy: 0.9373 - val_loss: 17.2320 - val_accuracy: 0.0476\n",
      "Epoch 184/300\n",
      "18/18 [==============================] - 4s 240ms/step - loss: 0.1881 - accuracy: 0.9355 - val_loss: 17.4142 - val_accuracy: 0.0159\n",
      "Epoch 185/300\n",
      "18/18 [==============================] - 6s 306ms/step - loss: 0.2344 - accuracy: 0.9301 - val_loss: 18.1217 - val_accuracy: 0.0476\n",
      "Epoch 186/300\n",
      "18/18 [==============================] - 6s 318ms/step - loss: 0.2743 - accuracy: 0.9140 - val_loss: 17.7038 - val_accuracy: 0.0476\n",
      "Epoch 187/300\n",
      "18/18 [==============================] - 8s 454ms/step - loss: 0.3262 - accuracy: 0.9032 - val_loss: 16.9422 - val_accuracy: 0.0317\n",
      "Epoch 188/300\n",
      "18/18 [==============================] - 7s 409ms/step - loss: 0.2806 - accuracy: 0.9086 - val_loss: 17.7254 - val_accuracy: 0.0476\n",
      "Epoch 189/300\n",
      "18/18 [==============================] - 6s 335ms/step - loss: 0.2546 - accuracy: 0.9086 - val_loss: 17.7023 - val_accuracy: 0.0476\n",
      "Epoch 190/300\n",
      "18/18 [==============================] - 6s 338ms/step - loss: 0.2292 - accuracy: 0.9211 - val_loss: 17.2540 - val_accuracy: 0.0317\n",
      "Epoch 191/300\n",
      "18/18 [==============================] - 6s 343ms/step - loss: 0.2024 - accuracy: 0.9391 - val_loss: 17.5855 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/300\n",
      "18/18 [==============================] - 6s 335ms/step - loss: 0.2745 - accuracy: 0.9283 - val_loss: 17.9886 - val_accuracy: 0.0159\n",
      "Epoch 193/300\n",
      "18/18 [==============================] - 6s 330ms/step - loss: 0.2928 - accuracy: 0.8996 - val_loss: 17.5123 - val_accuracy: 0.0159\n",
      "Epoch 194/300\n",
      "18/18 [==============================] - 6s 316ms/step - loss: 0.2486 - accuracy: 0.9140 - val_loss: 17.7577 - val_accuracy: 0.0159\n",
      "Epoch 195/300\n",
      "18/18 [==============================] - 6s 338ms/step - loss: 0.2529 - accuracy: 0.9194 - val_loss: 17.0967 - val_accuracy: 0.0476\n",
      "Epoch 196/300\n",
      "18/18 [==============================] - 6s 346ms/step - loss: 0.1742 - accuracy: 0.9427 - val_loss: 17.7461 - val_accuracy: 0.0476\n",
      "Epoch 197/300\n",
      "18/18 [==============================] - 6s 331ms/step - loss: 0.1896 - accuracy: 0.9462 - val_loss: 17.6322 - val_accuracy: 0.0476\n",
      "Epoch 198/300\n",
      "18/18 [==============================] - 5s 297ms/step - loss: 0.2230 - accuracy: 0.9158 - val_loss: 18.1876 - val_accuracy: 0.0476\n",
      "Epoch 199/300\n",
      "18/18 [==============================] - 5s 302ms/step - loss: 0.1556 - accuracy: 0.9498 - val_loss: 18.0465 - val_accuracy: 0.0317\n",
      "Epoch 200/300\n",
      "18/18 [==============================] - 5s 305ms/step - loss: 0.1614 - accuracy: 0.9462 - val_loss: 18.0984 - val_accuracy: 0.0635\n",
      "Epoch 201/300\n",
      "18/18 [==============================] - 5s 301ms/step - loss: 0.1735 - accuracy: 0.9427 - val_loss: 18.7249 - val_accuracy: 0.0476\n",
      "Epoch 202/300\n",
      "18/18 [==============================] - 6s 307ms/step - loss: 0.2336 - accuracy: 0.9229 - val_loss: 18.8209 - val_accuracy: 0.0476\n",
      "Epoch 203/300\n",
      "18/18 [==============================] - 5s 305ms/step - loss: 0.5058 - accuracy: 0.8728 - val_loss: 18.1246 - val_accuracy: 0.0317\n",
      "Epoch 204/300\n",
      "18/18 [==============================] - 5s 301ms/step - loss: 0.3409 - accuracy: 0.8763 - val_loss: 17.5061 - val_accuracy: 0.0159\n",
      "Epoch 205/300\n",
      "18/18 [==============================] - 5s 302ms/step - loss: 0.3000 - accuracy: 0.9050 - val_loss: 17.0267 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/300\n",
      "18/18 [==============================] - 5s 305ms/step - loss: 0.2490 - accuracy: 0.9086 - val_loss: 17.2091 - val_accuracy: 0.0159\n",
      "Epoch 207/300\n",
      "18/18 [==============================] - 5s 301ms/step - loss: 0.1952 - accuracy: 0.9337 - val_loss: 17.4448 - val_accuracy: 0.0476\n",
      "Epoch 208/300\n",
      "18/18 [==============================] - 6s 327ms/step - loss: 0.1730 - accuracy: 0.9301 - val_loss: 17.8769 - val_accuracy: 0.0159\n",
      "Epoch 209/300\n",
      "18/18 [==============================] - 6s 332ms/step - loss: 0.1851 - accuracy: 0.9391 - val_loss: 17.7935 - val_accuracy: 0.0159\n",
      "Epoch 210/300\n",
      "18/18 [==============================] - 5s 301ms/step - loss: 0.1949 - accuracy: 0.9427 - val_loss: 18.6170 - val_accuracy: 0.0476\n",
      "Epoch 211/300\n",
      "18/18 [==============================] - 6s 307ms/step - loss: 0.2224 - accuracy: 0.9301 - val_loss: 18.2444 - val_accuracy: 0.0159\n",
      "Epoch 212/300\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.3318 - accuracy: 0.9050 - val_loss: 18.1511 - val_accuracy: 0.0476\n",
      "Epoch 213/300\n",
      "18/18 [==============================] - 5s 300ms/step - loss: 0.2920 - accuracy: 0.9068 - val_loss: 16.9363 - val_accuracy: 0.0159\n",
      "Epoch 214/300\n",
      "18/18 [==============================] - 6s 359ms/step - loss: 0.2740 - accuracy: 0.9194 - val_loss: 17.6202 - val_accuracy: 0.0476\n",
      "Epoch 215/300\n",
      "18/18 [==============================] - 6s 329ms/step - loss: 0.2378 - accuracy: 0.9409 - val_loss: 16.5103 - val_accuracy: 0.0476\n",
      "Epoch 216/300\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2146 - accuracy: 0.9301 - val_loss: 17.0886 - val_accuracy: 0.0317\n",
      "Epoch 217/300\n",
      "18/18 [==============================] - 6s 341ms/step - loss: 0.1782 - accuracy: 0.9409 - val_loss: 17.5905 - val_accuracy: 0.0317\n",
      "Epoch 218/300\n",
      "18/18 [==============================] - 6s 349ms/step - loss: 0.1773 - accuracy: 0.9427 - val_loss: 17.6543 - val_accuracy: 0.0476\n",
      "Epoch 219/300\n",
      "18/18 [==============================] - 6s 316ms/step - loss: 0.1560 - accuracy: 0.9444 - val_loss: 17.6915 - val_accuracy: 0.0476\n",
      "Epoch 220/300\n",
      "18/18 [==============================] - 5s 300ms/step - loss: 0.1451 - accuracy: 0.9444 - val_loss: 18.2333 - val_accuracy: 0.0317\n",
      "Epoch 221/300\n",
      "18/18 [==============================] - 5s 297ms/step - loss: 0.1445 - accuracy: 0.9570 - val_loss: 18.3335 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/300\n",
      "18/18 [==============================] - 5s 299ms/step - loss: 0.1466 - accuracy: 0.9624 - val_loss: 18.8461 - val_accuracy: 0.0159\n",
      "Epoch 223/300\n",
      "18/18 [==============================] - 5s 301ms/step - loss: 0.1358 - accuracy: 0.9570 - val_loss: 18.6935 - val_accuracy: 0.0317\n",
      "Epoch 224/300\n",
      "18/18 [==============================] - 5s 297ms/step - loss: 0.1387 - accuracy: 0.9516 - val_loss: 18.4981 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/300\n",
      "18/18 [==============================] - 6s 307ms/step - loss: 0.1643 - accuracy: 0.9516 - val_loss: 18.2322 - val_accuracy: 0.0317\n",
      "Epoch 226/300\n",
      "18/18 [==============================] - 5s 298ms/step - loss: 0.1584 - accuracy: 0.9570 - val_loss: 18.3965 - val_accuracy: 0.0317\n",
      "Epoch 227/300\n",
      "18/18 [==============================] - 5s 300ms/step - loss: 0.2148 - accuracy: 0.9355 - val_loss: 18.1150 - val_accuracy: 0.0317\n",
      "Epoch 228/300\n",
      "18/18 [==============================] - 5s 299ms/step - loss: 0.2406 - accuracy: 0.9176 - val_loss: 18.9802 - val_accuracy: 0.0159\n",
      "Epoch 229/300\n",
      "18/18 [==============================] - 6s 332ms/step - loss: 0.1896 - accuracy: 0.9462 - val_loss: 18.1520 - val_accuracy: 0.0159\n",
      "Epoch 230/300\n",
      "18/18 [==============================] - 6s 331ms/step - loss: 0.1560 - accuracy: 0.9552 - val_loss: 18.8246 - val_accuracy: 0.0159\n",
      "Epoch 231/300\n",
      "18/18 [==============================] - 6s 338ms/step - loss: 0.1482 - accuracy: 0.9534 - val_loss: 19.0293 - val_accuracy: 0.0317\n",
      "Epoch 232/300\n",
      "18/18 [==============================] - 6s 333ms/step - loss: 0.1472 - accuracy: 0.9570 - val_loss: 18.8153 - val_accuracy: 0.0317\n",
      "Epoch 233/300\n",
      "18/18 [==============================] - 5s 301ms/step - loss: 0.1357 - accuracy: 0.9534 - val_loss: 18.6635 - val_accuracy: 0.0317\n",
      "Epoch 234/300\n",
      "18/18 [==============================] - 6s 334ms/step - loss: 0.1311 - accuracy: 0.9552 - val_loss: 19.0008 - val_accuracy: 0.0317\n",
      "Epoch 235/300\n",
      "18/18 [==============================] - 5s 302ms/step - loss: 0.2019 - accuracy: 0.9498 - val_loss: 18.3724 - val_accuracy: 0.0317\n",
      "Epoch 236/300\n",
      "18/18 [==============================] - 5s 296ms/step - loss: 0.1318 - accuracy: 0.9588 - val_loss: 17.5983 - val_accuracy: 0.0317\n",
      "Epoch 237/300\n",
      "18/18 [==============================] - 5s 300ms/step - loss: 0.1465 - accuracy: 0.9624 - val_loss: 18.6554 - val_accuracy: 0.0159\n",
      "Epoch 238/300\n",
      "18/18 [==============================] - 5s 299ms/step - loss: 0.1449 - accuracy: 0.9588 - val_loss: 18.0444 - val_accuracy: 0.0159\n",
      "Epoch 239/300\n",
      "18/18 [==============================] - 6s 310ms/step - loss: 0.1516 - accuracy: 0.9552 - val_loss: 18.1849 - val_accuracy: 0.0476\n",
      "Epoch 240/300\n",
      "18/18 [==============================] - 5s 303ms/step - loss: 0.1351 - accuracy: 0.9588 - val_loss: 18.3652 - val_accuracy: 0.0159\n",
      "Epoch 241/300\n",
      "18/18 [==============================] - 5s 301ms/step - loss: 0.1421 - accuracy: 0.9659 - val_loss: 18.4136 - val_accuracy: 0.0317\n",
      "Epoch 242/300\n",
      "18/18 [==============================] - 5s 296ms/step - loss: 0.1160 - accuracy: 0.9695 - val_loss: 18.7905 - val_accuracy: 0.0159\n",
      "Epoch 243/300\n",
      "18/18 [==============================] - 6s 312ms/step - loss: 0.1018 - accuracy: 0.9695 - val_loss: 19.4370 - val_accuracy: 0.0159\n",
      "Epoch 244/300\n",
      "18/18 [==============================] - 6s 312ms/step - loss: 0.1219 - accuracy: 0.9695 - val_loss: 19.2053 - val_accuracy: 0.0317\n",
      "Epoch 245/300\n",
      "18/18 [==============================] - 5s 301ms/step - loss: 0.1526 - accuracy: 0.9444 - val_loss: 19.4160 - val_accuracy: 0.0159\n",
      "Epoch 246/300\n",
      "18/18 [==============================] - 5s 301ms/step - loss: 0.1531 - accuracy: 0.9588 - val_loss: 19.0300 - val_accuracy: 0.0159\n",
      "Epoch 247/300\n",
      "18/18 [==============================] - 5s 302ms/step - loss: 0.1429 - accuracy: 0.9552 - val_loss: 19.4332 - val_accuracy: 0.0159\n",
      "Epoch 248/300\n",
      "18/18 [==============================] - 5s 300ms/step - loss: 0.2024 - accuracy: 0.9391 - val_loss: 18.7093 - val_accuracy: 0.0159\n",
      "Epoch 249/300\n",
      "18/18 [==============================] - 6s 339ms/step - loss: 0.1872 - accuracy: 0.9480 - val_loss: 18.8592 - val_accuracy: 0.0476\n",
      "Epoch 250/300\n",
      "18/18 [==============================] - 5s 299ms/step - loss: 0.1898 - accuracy: 0.9409 - val_loss: 18.6859 - val_accuracy: 0.0635\n",
      "Epoch 251/300\n",
      "18/18 [==============================] - 6s 315ms/step - loss: 0.6942 - accuracy: 0.8495 - val_loss: 18.0683 - val_accuracy: 0.0476\n",
      "Epoch 252/300\n",
      "18/18 [==============================] - 5s 304ms/step - loss: 0.5763 - accuracy: 0.8262 - val_loss: 16.4482 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/300\n",
      "18/18 [==============================] - 8s 430ms/step - loss: 0.5370 - accuracy: 0.8423 - val_loss: 17.3480 - val_accuracy: 0.0317\n",
      "Epoch 254/300\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.3286 - accuracy: 0.8889 - val_loss: 17.9880 - val_accuracy: 0.0317\n",
      "Epoch 255/300\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.3029 - accuracy: 0.8961 - val_loss: 17.5626 - val_accuracy: 0.0317\n",
      "Epoch 256/300\n",
      "18/18 [==============================] - 6s 356ms/step - loss: 0.2659 - accuracy: 0.9265 - val_loss: 18.0107 - val_accuracy: 0.0476\n",
      "Epoch 257/300\n",
      "18/18 [==============================] - 6s 337ms/step - loss: 0.1544 - accuracy: 0.9552 - val_loss: 17.9736 - val_accuracy: 0.0476\n",
      "Epoch 258/300\n",
      "18/18 [==============================] - 6s 337ms/step - loss: 0.1391 - accuracy: 0.9516 - val_loss: 18.5971 - val_accuracy: 0.0317\n",
      "Epoch 259/300\n",
      "18/18 [==============================] - 6s 336ms/step - loss: 0.1176 - accuracy: 0.9677 - val_loss: 19.2036 - val_accuracy: 0.0317\n",
      "Epoch 260/300\n",
      "18/18 [==============================] - 6s 346ms/step - loss: 0.1329 - accuracy: 0.9534 - val_loss: 19.1181 - val_accuracy: 0.0317\n",
      "Epoch 261/300\n",
      "18/18 [==============================] - 6s 338ms/step - loss: 0.1707 - accuracy: 0.9516 - val_loss: 19.4201 - val_accuracy: 0.0317\n",
      "Epoch 262/300\n",
      "18/18 [==============================] - 6s 331ms/step - loss: 0.1294 - accuracy: 0.9552 - val_loss: 19.1987 - val_accuracy: 0.0159\n",
      "Epoch 263/300\n",
      "18/18 [==============================] - 6s 353ms/step - loss: 0.1292 - accuracy: 0.9570 - val_loss: 19.5720 - val_accuracy: 0.0159\n",
      "Epoch 264/300\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1145 - accuracy: 0.9695 - val_loss: 19.2256 - val_accuracy: 0.0159\n",
      "Epoch 265/300\n",
      "18/18 [==============================] - 6s 355ms/step - loss: 0.0930 - accuracy: 0.9695 - val_loss: 19.7817 - val_accuracy: 0.0159\n",
      "Epoch 266/300\n",
      "18/18 [==============================] - 6s 339ms/step - loss: 0.1050 - accuracy: 0.9624 - val_loss: 20.0974 - val_accuracy: 0.0159\n",
      "Epoch 267/300\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.1026 - accuracy: 0.9659 - val_loss: 20.1644 - val_accuracy: 0.0159\n",
      "Epoch 268/300\n",
      "18/18 [==============================] - 6s 344ms/step - loss: 0.2050 - accuracy: 0.9319 - val_loss: 20.0189 - val_accuracy: 0.0317\n",
      "Epoch 269/300\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1526 - accuracy: 0.9516 - val_loss: 19.1590 - val_accuracy: 0.0476\n",
      "Epoch 270/300\n",
      "18/18 [==============================] - 6s 337ms/step - loss: 0.1799 - accuracy: 0.9516 - val_loss: 19.4048 - val_accuracy: 0.0159\n",
      "Epoch 271/300\n",
      "18/18 [==============================] - 6s 332ms/step - loss: 0.1664 - accuracy: 0.9427 - val_loss: 19.1930 - val_accuracy: 0.0317\n",
      "Epoch 272/300\n",
      "18/18 [==============================] - 6s 330ms/step - loss: 0.0974 - accuracy: 0.9713 - val_loss: 19.1712 - val_accuracy: 0.0317\n",
      "Epoch 273/300\n",
      "18/18 [==============================] - 6s 330ms/step - loss: 0.1190 - accuracy: 0.9588 - val_loss: 19.3890 - val_accuracy: 0.0317\n",
      "Epoch 274/300\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1071 - accuracy: 0.9624 - val_loss: 19.3822 - val_accuracy: 0.0476\n",
      "Epoch 275/300\n",
      "18/18 [==============================] - 6s 337ms/step - loss: 0.0977 - accuracy: 0.9606 - val_loss: 19.9555 - val_accuracy: 0.0317\n",
      "Epoch 276/300\n",
      "18/18 [==============================] - 6s 327ms/step - loss: 0.0690 - accuracy: 0.9821 - val_loss: 20.2224 - val_accuracy: 0.0317\n",
      "Epoch 277/300\n",
      "18/18 [==============================] - 6s 349ms/step - loss: 0.0936 - accuracy: 0.9642 - val_loss: 20.7152 - val_accuracy: 0.0317\n",
      "Epoch 278/300\n",
      "18/18 [==============================] - 6s 334ms/step - loss: 0.1458 - accuracy: 0.9462 - val_loss: 20.8726 - val_accuracy: 0.0317\n",
      "Epoch 279/300\n",
      "18/18 [==============================] - 7s 365ms/step - loss: 0.1256 - accuracy: 0.9534 - val_loss: 20.7742 - val_accuracy: 0.0159\n",
      "Epoch 280/300\n",
      "18/18 [==============================] - 6s 351ms/step - loss: 0.1590 - accuracy: 0.9516 - val_loss: 20.4015 - val_accuracy: 0.0476\n",
      "Epoch 281/300\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1201 - accuracy: 0.9677 - val_loss: 19.7952 - val_accuracy: 0.0317\n",
      "Epoch 282/300\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1377 - accuracy: 0.9606 - val_loss: 20.5714 - val_accuracy: 0.0159\n",
      "Epoch 283/300\n",
      "18/18 [==============================] - 8s 426ms/step - loss: 0.1133 - accuracy: 0.9570 - val_loss: 20.4639 - val_accuracy: 0.0317\n",
      "Epoch 284/300\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1102 - accuracy: 0.9659 - val_loss: 20.3937 - val_accuracy: 0.0317\n",
      "Epoch 285/300\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.0704 - accuracy: 0.9803 - val_loss: 21.4368 - val_accuracy: 0.0476\n",
      "Epoch 286/300\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1515 - accuracy: 0.9570 - val_loss: 21.7125 - val_accuracy: 0.0476\n",
      "Epoch 287/300\n",
      "18/18 [==============================] - 6s 312ms/step - loss: 0.1672 - accuracy: 0.9516 - val_loss: 20.7978 - val_accuracy: 0.0317\n",
      "Epoch 288/300\n",
      "18/18 [==============================] - 6s 332ms/step - loss: 0.1080 - accuracy: 0.9713 - val_loss: 20.1443 - val_accuracy: 0.0317\n",
      "Epoch 289/300\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.1088 - accuracy: 0.9570 - val_loss: 20.6488 - val_accuracy: 0.0159\n",
      "Epoch 290/300\n",
      "18/18 [==============================] - 6s 342ms/step - loss: 0.1726 - accuracy: 0.9337 - val_loss: 20.4955 - val_accuracy: 0.0317\n",
      "Epoch 291/300\n",
      "18/18 [==============================] - 6s 335ms/step - loss: 0.1103 - accuracy: 0.9642 - val_loss: 21.3073 - val_accuracy: 0.0159\n",
      "Epoch 292/300\n",
      "18/18 [==============================] - 6s 311ms/step - loss: 0.1251 - accuracy: 0.9570 - val_loss: 20.0027 - val_accuracy: 0.0159\n",
      "Epoch 293/300\n",
      "18/18 [==============================] - 5s 305ms/step - loss: 0.0891 - accuracy: 0.9695 - val_loss: 19.6017 - val_accuracy: 0.0476\n",
      "Epoch 294/300\n",
      "18/18 [==============================] - 6s 307ms/step - loss: 0.1087 - accuracy: 0.9570 - val_loss: 20.1724 - val_accuracy: 0.0159\n",
      "Epoch 295/300\n",
      "18/18 [==============================] - 6s 311ms/step - loss: 0.1769 - accuracy: 0.9444 - val_loss: 20.1618 - val_accuracy: 0.0159\n",
      "Epoch 296/300\n",
      "18/18 [==============================] - 6s 357ms/step - loss: 0.1697 - accuracy: 0.9588 - val_loss: 20.4621 - val_accuracy: 0.0317\n",
      "Epoch 297/300\n",
      "18/18 [==============================] - 6s 305ms/step - loss: 0.3018 - accuracy: 0.9068 - val_loss: 21.0911 - val_accuracy: 0.0317\n",
      "Epoch 298/300\n",
      "18/18 [==============================] - 6s 309ms/step - loss: 0.3815 - accuracy: 0.9068 - val_loss: 20.0579 - val_accuracy: 0.0317\n",
      "Epoch 299/300\n",
      "18/18 [==============================] - 6s 312ms/step - loss: 0.2585 - accuracy: 0.9247 - val_loss: 19.6638 - val_accuracy: 0.0159\n",
      "Epoch 300/300\n",
      "18/18 [==============================] - 6s 328ms/step - loss: 0.2963 - accuracy: 0.9104 - val_loss: 18.8038 - val_accuracy: 0.0317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2800f707050>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=1000,validation_split=0.1,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 106ms/step - loss: 19.6131 - accuracy: 0.0064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[19.61314582824707, 0.006410256493836641]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model03.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('model03.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
